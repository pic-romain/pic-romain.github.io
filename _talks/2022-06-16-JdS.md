---
title: "53e Journées de Statistique"
collection: talks
type: "Talk"
permalink: /talks/2022-06-16-JdS
venue: "Université Claude Bernard Lyon 1"
date: 2022-06-16
location: "Lyon, France"
---
Talk in French for the [53e Journées de Statistique](https://jds22.sciencesconf.org/) de la SFDS, organized in Lyon (France).

**Title.** Minimax Rate of Convergence for Distributional Regression using the Continuous Ranked Probability Score

**Abstract.** The distributional regression fulfills a fundamental need of statistical analysis : being able to make forecasts and quantify their uncertainty. This approach overcomes the limits of classical regression which estimates only the conditional mean by estimation the whole distribution law. This methodology, called probabilistic forecast, is widely used in numerous fields such as meteorology and energy production, but its theoretical aspects have not been studied. By analogy with the classical theory of statistical learning, we define a framework where the predictor is a law of probability, called prediction law, and where the loss function is given by a strictly proper scoring rule in the sense of [Gneiting and Raftery (2007)](http://www.stat.washington.edu/raftery/Research/PDF/Gneiting2007jasa.pdf). Bayes predictor is then the conditional law. In the case of the
Continuous Ranked Probability Score, we study then the minimax rate of convergence and show that the k nearest neighbor algorithm reaches the optimal rate of convergence in dimension higher or equal to 2 and that the kernel methods reach this optimal rate in any dimension.

**Long summary in French** : [here](https://jds22.sciencesconf.org/392650)
**Associated article** : Distributional regression and its evaluation with the CRPS: Bounds and convergence of the minimax risk, Pic et al. (2022) [link](../publications/2022-10-28-CRPS_Convergence)
